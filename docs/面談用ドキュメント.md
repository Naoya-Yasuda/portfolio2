# 面談用ドキュメント

## 想定Q&A

### Q: 数理最適化の経験はありますか？

マナビDXクエストでLightGBMによる充填率予測を実装し、そのアウトプットを元にドライバーの回収経路を数理最適化する活用方法を提案しました。数理最適化は「AIモデルを作る」というより「問題を数式で定義してソルバーに解かせる」分野であり、予測→最適化のパイプラインについては理解しています。

### Q: ローカルLLMの構築経験はありますか？

DGX Stationのお話から、データをクラウドに出せないセキュリティ要件があると理解しました。

ローカルLLM環境の構築経験としては、DevSecOpsThonにてH100実機にSSH接続し、GPUリソースを複数チームに分割した環境で開発した経験があります（クラウド経由ではなくオンプレミス環境）。NVIDIA NGC等のコンテナイメージを使えば、クラウドとローカルで環境構築の手順は大きく変わらないと認識しています。

DGX Stationもチーム共有が前提となるため、MIG等でリソースを分割しながら複数メンバーが同時に開発する運用になるかと思います。実機は所有していませんが、兼業先ではDGX Sparkの導入が進んでおり、必要に応じてキャッチアップ可能です。

VPN経由でのリモート接続が必要な認識です。VPN接続用の認証情報はご共有いただき、SSH鍵は私の方で生成・管理し公開鍵をお渡しする形で環境構築しVLMの追加学習をしていくと思っています。

環境構築としては、NGCからPyTorchコンテナをプルし、Hugging FaceからQwen3-VL等のモデルをダウンロードする形になるかと思います。

### Q: ファインチューニングの経験はありますか？

AWS SageMakerでLoRAを用いたファインチューニング経験があります。官公庁の公開文書をインプットに、業務要件に応じたモデルの追加学習を検証しました。優先度の高いタスクが発生したため検証フェーズで終了しましたが、結果として公用語でのトーン統一は一定レベルまで達成しました。ただし、現在のモデルであればプロンプトエンジニアリングで十分対応可能です。

### Q: RAGの構築経験はありますか？

DevSecOpsThonにてRAGシステムをフルスクラッチで構築した経験があります。ベクトルDB、画面、APIサーバをモノリポ構成でDockerコンテナ化し、一気通貫で開発しました。現在はDifyやAWS Bedrock Knowledge Basesなど、マネージドサービスでRAGを簡易に構築可能です。AWSではベクトルストアとしてOpenSearchやS3 Vectorsを選択でき、S3にドキュメントを配置するだけでBedrockが自動でチャンク分割・埋め込み生成・ベクトルインデックス作成まで行ってくれます。

---

## 案件理解

### VLMの役割

VLMは「生成」ではなく「解釈」が主役。原子力分野では既存のExcelテンプレートが正解であり、VLMはPDF→テンプレへの転記精度を上げる役割。

### ワークフロー理解

```
PDF → レイアウト解析（Docling等） → VLMで解釈 → AIレビュー → 既存Excelテンプレへ転記
```

「AIが新フォーマットを生成」ではなく「人が作った帳票を再現」する構成。

### 音声制御AIエージェント（Unitree案件）

**基本設計思想：**
単に「音声→テキスト→LLM」ではなく、現場運用を想定したパイプライン設計。

**ハイブリッド構成：**
- ロボ側（Unitree）：安全クリティカルな制御・SDK実行
- エッジ側（同一LAN上）：ASR/NLUなど重い推論処理

**処理フロー：**
```
音声入力 → VAD区間抽出 → ASR（Whisper系）→ 専門語補正（辞書＋ファジーマッチで略語/型番/表記揺れを正規化）→ NLU（意図・スロットをJSON構造化）→ Safety Gate（速度・立入禁止・危険動作を審査、必要なら確認質問）→ SDK実行
```

**並列/直列制御：**
- 推論（ASR/NLU）は並列処理可
- 制御（ロボ命令）は直列処理
- STOPコマンドだけは割り込み最優先で即時実行

**セキュリティ設計：**
- 到達制御：VPN/IP制限
- 機器認証：mTLS等
- 改ざん防止：署名付きコマンド（HMAC/短命トークン）
- → 正当なエッジからの命令だけ受け付ける設計

**監査ログ：**
音声→テキスト→意図JSON→承認理由→実行結果まで一気通貫で記録
→ 再現性と改善サイクル（辞書・ルール・プロンプトの更新）を確保

**PoC重視点：**
- 「STOPなど安全コマンドを最優先」
- 「入力サイズや同時実行数を制限して落ちない」
- → 短期間でも現場投入できる形に仕上げる

---

## 今回要件に合わせた「勝ち筋」まとめ（おすすめ構成）

### 推奨アーキテクチャ

```
Docling（レイアウト解析・表抽出）
  ↓
Qwen3-VL（図面・手書き等の解釈）
  ↓
AIレビュー（抽出結果の整合性チェック）
  ↓
既存Excelテンプレートへ転記
```

### Doclingを推す理由

- PDF構造抽出に特化、MCP Serverあり
- RT-DETRベースでDocLayNetラベル（表・図・見出し等）を検出
- TableFormerで表セル単位の抽出が可能
- Apache 2.0ライセンスで商用利用可

---

## それでも"AIレビュー"が効く領域

- 単位の整合性チェック（kW ↔ MW、mm ↔ m）
- 数値の桁ズレ・転記ミス検出
- 必須項目の欠落検知
- 過去データとの異常値比較

→ 100%自動化ではなく「人間レビュー前のフィルタ」として提案すると刺さりやすい

---

## 抽出モデル選定

### RT-DETR（Docling標準）

- 精度重視、DocLayNetラベル対応
- 商用利用OK（Apache 2.0）

### DocLayout-YOLO

- 速度重視の場合の選択肢
- AGPLライセンス → 商用利用時は注意（ソース公開義務）

### TableFormer

- 表のセル単位抽出に特化
- Doclingと組み合わせて使用

---

## 面談で強い「KPI例」

- 転記エラー率：○%削減
- 処理時間：1件あたり○分→○秒
- 人的レビュー工数：○%削減
- 年間コスト削減額：○万円

→ 定量的な目標設定ができることをアピール

---

## DGX/オンプレ/ローカルLLMへの答え方

「クラウドに出せないデータを扱う要件は理解しています。H100実機でのGPU開発経験があり、NGCコンテナを使えばクラウドとローカルで環境構築手順は大きく変わりません。DGX Stationは実機未所有ですが、兼業先でも導入が進んでおりキャッチアップ可能です。」

---

## 逆にあなたから聞くべき質問

- PDFのサンプルを事前に共有いただくことは可能ですか？（構造把握のため）
- 既存Excelテンプレートの項目数・複雑さはどの程度ですか？
- 精度目標（許容エラー率）の目安はありますか？
- 2ヶ月の期間でPoC完了が目標ですか、それとも本番運用開始まで含みますか？
- VLM以外の選択肢（OCR + ルールベース等）は検討されましたか？

---

## 技術キーワード一覧

| カテゴリ | キーワード |
|---------|-----------|
| AI駆動開発ツール | Claude Code, Cursor, Codex, ChatGPT, Gemini |
| AIエージェント | Google ADK, A2A, browser-use, n8n |
| 機械学習・ファインチューニング | LightGBM, TF-IDF, Mecab, LoRA, SageMaker, VLM, Qwen3-VL |
| 動画生成AI | Sora2, Veo3.1, Kling, nano banana |
| RAG | ベクトルDB, Dify, Bedrock Knowledge Bases |
| クラウド・データ基盤 | AWS, Snowflake, Google Analytics |
| GPU環境 | H100, NVIDIA NGC, MIG, DGX Station（キャッチアップ可） |
| 文書解析・レイアウト抽出 | Docling, RT-DETR, TableFormer, DocLayout-YOLO, DocLayNet |
| 音声制御・ロボティクス | VAD, ASR, Whisper, NLU, Safety Gate, mTLS, HMAC, Unitree SDK |
